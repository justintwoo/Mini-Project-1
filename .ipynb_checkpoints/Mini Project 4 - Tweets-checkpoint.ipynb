{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/gioong/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/gioong/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install tweepy\n",
    "#!pip install preprocessor\n",
    "#!pip install textblob\n",
    "import os\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "import re\n",
    "import string\n",
    "\n",
    "import preprocessor as p\n",
    "import csv\n",
    "import sys\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords') \n",
    "nltk.download('punkt')\n",
    "#from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'api' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e2f664c55226>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0maccess_secret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'r9bokM5UvRbS8QnsYdQksSi2tO8gRj7T4sfq2K41jzmQM'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_timeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'MentorworksISA'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'extended'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"searchTweets.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0malltweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'api' is not defined"
     ]
    }
   ],
   "source": [
    "#Authenticate credentials\n",
    "\n",
    "#Twitter credentials for the app\n",
    "'''\n",
    "consumer_key = 'lIJoTxgYaPqqhcMWOijuVAJFh'\n",
    "consumer_secret = '6gg1DnFzDLHpxZ8kAIC7uJvqjjcZ2nuswFQcrgacwCybDuvpbs'\n",
    "access_key= '1432859916277063683-laTobVIjk69Xa91kWn3YmuqGoXtoxO'\n",
    "access_secret = 'waKE7HTEcsiFsauOzz69aUcQEI2qY6ZHBJKtY8GCiCAMs'\n",
    "'''\n",
    "consumer_key = 'ELRou1VKpS5p7EBEGamXqqGRT'\n",
    "consumer_secret = 'QbsToHJOyA9ZsDrFCCw1aErF9LubwqlfLpLcJviruhKepQwX3D'\n",
    "access_key= '3138259520-6jOClvoHXzF5DCf2XaylTxhrn1Rb7X50ykQyU3C'\n",
    "access_secret = 'r9bokM5UvRbS8QnsYdQksSi2tO8gRj7T4sfq2K41jzmQM'\n",
    "\n",
    "tweets = tweepy.Cursor(api.user_timeline, screen_name='MentorworksISA',lang='en', tweet_mode = 'extended').items(10)\n",
    "file = open(\"searchTweets.csv\", 'a',newline='')\n",
    "alltweets = csv.writer(file)\n",
    "#for page in tweets:\n",
    "#        for status in page:\n",
    "#            new_entry = []\n",
    "#            status = status._json\n",
    "#            print(status)\n",
    "#            print(status['created_at'])\n",
    "for tweet in tweets:\n",
    "    status = tweet._json\n",
    "    #print(status)\n",
    "    created_at =  status['created_at'] # accessing tweet time\n",
    "    tweet_id = status['id_str']         # accessing tweet id\n",
    "    tweet_text = status['full_text']     # accessing tweet text\n",
    "    tweet_text = re.sub(r'\\W',' ', tweet_text) # Remove special characters    \n",
    "    print(tweet_text)\n",
    "    alltweets.writerow([created_at, tweet_id, tweet_text])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analysis\n",
    "\n",
    "file =open(\"searchTweets.csv\", 'r')\n",
    "alltweets = csv.reader(file)\n",
    "\n",
    "sentiment_file = open(\"sentimenttweets.csv\", \"w\",newline='')\n",
    "sntTweets = csv.writer(sentiment_file)\n",
    "\n",
    "for row in alltweets:\n",
    "    blob = TextBlob(row[2])\n",
    "    print(blob.sentiment.subjectivity)\n",
    "    if blob.sentiment.polarity > 0:   \n",
    "        sntTweets.writerow([row[0], row[1], row[2], blob.sentiment.polarity, \"positive\"])\n",
    "    elif blob.sentiment.polarity < 0:\n",
    "        sntTweets.writerow([row[0], row[1], row[2], blob.sentiment.polarity, \"negative\"])\n",
    "    elif blob.sentiment.polarity == 0.0:\n",
    "        sntTweets.writerow([row[0], row[1], row[2], blob.sentiment.polarity, \"neutral\"])   \n",
    "        \n",
    "file.close()\n",
    "sentiment_file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import Word\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "# Tokenization\n",
    "\n",
    "file =open(\"searchTweets.csv\", 'r')\n",
    "alltweets = csv.reader(file)\n",
    "\n",
    "tweet_line =alltweets.__next__()[2]\n",
    "\n",
    "print(tweet_line)\n",
    "\n",
    "blob = TextBlob(tweet_line)\n",
    "print(blob.words)\n",
    "print(blob.sentences)\n",
    "print(blob.sentiment)\n",
    "# Stemming and Lemmatization\n",
    " \n",
    "#print(blob.words[23])\n",
    "print('####Singularization###')\n",
    "print(blob.words[1])\n",
    "print(blob.words[1].singularize())\n",
    "\n",
    "print('####Pluralization###')\n",
    "print(blob.words[2])\n",
    "print(blob.words[2].pluralize())\n",
    "\n",
    "print('####Lemmatization###')\n",
    "print(blob.words[3])\n",
    "w=Word(blob.words[3])\n",
    "print(w.lemmatize(\"v\"))\n",
    "\n",
    "### # Spelling correction\n",
    "b = TextBlob(\"I havv goood speling!\")\n",
    "print(b.correct())\n",
    "\n",
    "file.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
