{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# -- Sheet --\n",
    "\n",
    "import pandas as pd \n",
    "import re\n",
    "import os\n",
    "import string\n",
    "import csv\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ticker                         created            id  polarity sentiment  \\\n",
      "0    MMM  Thu Mar 31 22:51:05 +0000 2022  1.510000e+18  1.000000  positive   \n",
      "1    MMM  Thu Mar 31 22:30:02 +0000 2022  1.510000e+18  0.275000  positive   \n",
      "2    MMM  Thu Mar 31 20:28:37 +0000 2022  1.510000e+18  0.106667  positive   \n",
      "3    MMM  Thu Mar 31 17:33:06 +0000 2022  1.510000e+18  1.000000  positive   \n",
      "4    MMM  Tue Mar 29 23:03:05 +0000 2022  1.510000e+18  1.000000  positive   \n",
      "\n",
      "   subjectivity  \n",
      "0      0.300000  \n",
      "1      0.500000  \n",
      "2      0.526667  \n",
      "3      0.300000  \n",
      "4      0.300000  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>0.012653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AOS</td>\n",
       "      <td>-0.013987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABT</td>\n",
       "      <td>-0.023078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>0.007997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABMD</td>\n",
       "      <td>0.039578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker    change\n",
       "0    MMM  0.012653\n",
       "1    AOS -0.013987\n",
       "2    ABT -0.023078\n",
       "3   ABBV  0.007997\n",
       "4   ABMD  0.039578"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data = pd.read_csv(\"sentimenttweets.csv\")\n",
    "'''\n",
    "# tweet_data = pd.concat([pd.read_excel(os.path.join(\"twitterdata\", f), index_col = 0) for f in os.listdir(\"twitterdata\")])\n",
    "\n",
    "tweet_data = pd.read_csv(\"searchTweets.csv\")\n",
    "\n",
    "tweet_data = tweet_data[[\"ticker\", \"created\", \"sent_score\"]]\n",
    "\n",
    "tweet_data2 = tweet_data2[[\"ticker\", \"created\", \"sent_score\"]]\n",
    "\n",
    "tweet_data = pd.concat([tweet_data, tweet_data2], axis = 0)\n",
    "\n",
    "tweet_data.shape\n",
    "\n",
    "'''\n",
    "print(tweet_data.head())\n",
    "\n",
    "\n",
    "returns_data = pd.read_csv(\"stocks.csv\")\n",
    "\n",
    "returns_data.head()\n",
    "\n",
    "# returns_data.reset_index(inplace = True)\n",
    "\n",
    "# returns_data[\"Date\"] = pd.to_datetime(returns_data[\"Date\"]).dt.strftime(\"%m-%d-%Y\")\n",
    "\n",
    "# returns_data.rename(columns = {\"level_0\": \"ticker\", \"Date\": \"date\"}, inplace = True)\n",
    "\n",
    "# returns_data.set_index([\"ticker\", \"date\"], inplace = True, drop = True)\n",
    "\n",
    "# returns_data = returns_data[[\"Volume\", \"Adj Close\"]]\n",
    "\n",
    "# returns = returns_data[\"Adj Close\"].groupby(level = 0).apply(lambda x: x / x[1:4].max())\n",
    "# vol = returns_data.groupby(level = 0)[\"Volume\"].apply(lambda x: x / x[1:4].max())\n",
    "\n",
    "# returns_data = pd.concat([returns, vol], axis = 1)\n",
    "# returns_data.rename(columns = {\"Adj Close\": \"return\", \"Volume\": \"vol\"}, inplace = True)\n",
    "# returns_data.dropna(inplace = True)\n",
    "\n",
    "# tweet_data.rename(columns = {\"created\": \"date\"}, inplace = True)\n",
    "# tweet_data.set_index([\"ticker\", \"date\"], inplace = True, drop = True)\n",
    "\n",
    "# # Drop any tweets with 0 sentiment (irrelevant/couldn't be parsed/etc.)\n",
    "\n",
    "# tweet_data = tweet_data[tweet_data[\"sent_score\"] != 0]\n",
    "\n",
    "# # Calculate average sentiment score by date\n",
    "\n",
    "# tweet_sent_data = tweet_data.groupby([\"ticker\", \"date\"])[\"sent_score\"].agg(['mean', 'count'])\n",
    "# tweet_sent_data.columns = [\"sent_score\", \"tweet_volume\"]\n",
    "# tweet_sent_data[\"tweet_volume\"] = tweet_sent_data.groupby(level = 0)[\"tweet_volume\"].apply(lambda x: x / x[1:4].max())\n",
    "\n",
    "# combined_data = returns_data.merge(tweet_sent_data, left_index = True, right_index = True, how = \"left\")\n",
    "\n",
    "# # In case of companies that didn't have any Twitter data for a particular date... \n",
    "# combined_data.fillna(0, inplace = True)\n",
    "\n",
    "# dt = combined_data.reset_index()\n",
    "\n",
    "# dt[\"date\"] = pd.to_datetime(dt[\"date\"])\n",
    "# dt.set_index([\"ticker\", \"date\"], inplace = True, drop = True)\n",
    "# dt.sort_index(level = 1, ascending = False, inplace = True)\n",
    "\n",
    "# target = dt[dt.index.get_level_values(1) == '11-27-2020']\n",
    "# features = dt[dt.index.get_level_values(1) != '11-27-2020']\n",
    "\n",
    "# target = target[\"return\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>id</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>1.510000e+18</td>\n",
       "      <td>0.161909</td>\n",
       "      <td>0.329144</td>\n",
       "      <td>-0.017591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAL</td>\n",
       "      <td>1.510000e+18</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.057178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>1.510000e+18</td>\n",
       "      <td>0.155000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.056476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>1.510000e+18</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.007997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABC</td>\n",
       "      <td>1.510000e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>WHR</td>\n",
       "      <td>1.510000e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.029015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>WM</td>\n",
       "      <td>1.510000e+18</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.001602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>WMT</td>\n",
       "      <td>1.510000e+18</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.362963</td>\n",
       "      <td>-0.005408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>WRK</td>\n",
       "      <td>1.510000e+18</td>\n",
       "      <td>0.191667</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.022383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>XOM</td>\n",
       "      <td>1.510000e+18</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.036496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticker            id  polarity  subjectivity    change\n",
       "0        A  1.510000e+18  0.161909      0.329144 -0.017591\n",
       "1      AAL  1.510000e+18  0.055000      0.140000  0.057178\n",
       "2     AAPL  1.510000e+18  0.155000      0.250000  0.056476\n",
       "3     ABBV  1.510000e+18  0.500000      0.150000  0.007997\n",
       "4      ABC  1.510000e+18  0.000000      0.000000  0.009858\n",
       "..     ...           ...       ...           ...       ...\n",
       "345    WHR  1.510000e+18  0.000000      0.000000 -0.029015\n",
       "346     WM  1.510000e+18  0.112500      0.300000  0.001602\n",
       "347    WMT  1.510000e+18  0.493827      0.362963 -0.005408\n",
       "348    WRK  1.510000e+18  0.191667      0.225000  0.022383\n",
       "349    XOM  1.510000e+18  0.333333      0.216667  0.036496\n",
       "\n",
       "[350 rows x 5 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_agg = tweet_data.groupby(['ticker'],as_index=False).mean()\n",
    "pd_data = tweet_agg.merge(returns_data)\n",
    "pd_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd_data['change']\n",
    "features = pd_data[['polarity','subjectivity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state = 0, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean_squared_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-1c1d7a39133f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mean_squared_error' is not defined"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model = model.fit(X_train, y_train)\n",
    "\n",
    "prediction = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, prediction)\n",
    "r2 = r2_score(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "train_tickers = list(random.sample(list(dt.index.get_level_values(0).unique()), 400))\n",
    "test_tickers = [x for x in dt.index.get_level_values(0).unique() if x not in train_tickers]\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "X_train = np.array([features[features.index.get_level_values(0) == ticker].values.tolist() for ticker in train_tickers])\n",
    "y_train = np.array([target[target.index.get_level_values(0) == ticker].values.tolist() for ticker in train_tickers])\n",
    "\n",
    "X_test = np.array([features[features.index.get_level_values(0) == ticker].values.tolist() for ticker in test_tickers])\n",
    "y_test = np.array([target[target.index.get_level_values(0) == ticker].values.tolist() for ticker in test_tickers])\n",
    "\n",
    "X_test[1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units = 10, return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "model.add(LSTM(units = 5))\n",
    "model.add(Dense(units = 1))\n",
    "\n",
    "early_stop = EarlyStopping(monitor='loss', patience=10, verbose=1)\n",
    "\n",
    "model.compile(optimizer = \"adam\", loss = \"mean_squared_error\")\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 50, batch_size = 30, callbacks=[early_stop])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "y_test_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(y_test, y_test_pred)\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "preds = pd.DataFrame({\"Predicted\": y_test_pred.flatten(), \"Actual\": y_test.flatten()})\n",
    "preds.plot()\n",
    "\n",
    "results = pd.DataFrame({\"Predicted\": y_test_pred.flatten(), \"Actual\": y_test.flatten()}, index = test_tickers)\n",
    "\n",
    "results.head()\n",
    "\n",
    "t_0 = features[features.index.get_level_values(1) == '11/25/2020'][[\"return\", \"sent_score\"]].reset_index(level = 1)\n",
    "\n",
    "res = results.merge(t_0, how = \"left\", left_index = True, right_index = True)\n",
    "\n",
    "res.rename(columns = {\"return\": \"t-1\"}, inplace = True)\n",
    "res.drop(columns = [\"date\"], inplace = True)\n",
    "\n",
    "res.head()\n",
    "\n",
    "ups = res[res[\"Predicted\"] > res[\"t-1\"]]\n",
    "\n",
    "downs = res[res[\"Predicted\"] < res[\"t-1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Ups: {} Downs: {}\".format(ups.shape[0], downs.shape[0]))\n",
    "\n",
    "print(\"Out of {} predicted ups, {} actually went up\".format(ups.shape[0], res[(res[\"Predicted\"] > res[\"t-1\"]) & (res[\"Actual\"] > res[\"t-1\"])].shape[0]))\n",
    "\n",
    "print(\"Out of {} predicted downs, {} actually went down\".format(downs.shape[0], res[(res[\"Predicted\"] < res[\"t-1\"]) & (res[\"Actual\"] < res[\"t-1\"])].shape[0]))\n",
    "\n",
    "abs_up_ret = (ups[\"Actual\"] - ups[\"t-1\"]).sum()\n",
    "print(\"If we bought equally-weighted shares of each predicted up, we would have made: {:.2f}\".format(abs_up_ret))\n",
    "print(\"Of a total investment of {:.2f}, that's a 1-day return of {:.2f}%\".format(ups[\"t-1\"].sum(), abs_up_ret / ups[\"t-1\"].sum() * 100))\n",
    "print(\"Annualized, that figure is {:.2f}%\".format((np.power(1 + abs_up_ret / ups[\"t-1\"].sum(), 251) - 1) * 100))\n",
    "\n",
    "abs_down_ret = (downs[\"t-1\"] - downs[\"Actual\"]).sum()\n",
    "print(\"If we shorted equally-weighted shares of each predicted down, we would have made: {:.2f}\".format(abs_down_ret))\n",
    "print(\"Of a total investment of {:.2f} (@150% margin), that's a 1-day return of {:.2f}%\".format(downs[\"t-1\"].sum() * 1.5, abs_down_ret / (downs[\"t-1\"].sum() * 1.5) * 100))\n",
    "print(\"Annualized, that figure is {:.2f}%\".format((np.power(1 + abs_down_ret / (downs[\"t-1\"].sum() * 1.5), 251) - 1) * 100))\n",
    "\n",
    "# Impact of sentiment on performance\n",
    "\n",
    "top_sent = res.nlargest(20, columns = \"sent_score\")\n",
    "low_sent = res.nsmallest(20, columns = \"sent_score\")\n",
    "\n",
    "print(\"Of 20 companies with highest sentiment at t-1, {} went up, {} went down\".format(top_sent[top_sent[\"Actual\"] > top_sent[\"t-1\"]].shape[0], top_sent[top_sent[\"Actual\"] < top_sent[\"t-1\"]].shape[0]))\n",
    "\n",
    "print(\"Equal-weighted price return (long highest sentiment companies): {:.2f}\".format((top_sent[\"Actual\"] - top_sent[\"t-1\"]).sum()))\n",
    "\n",
    "print(\"Of 20 companies with lowest sentiment at t-1, {} went up, {} went down\".format(low_sent[low_sent[\"Actual\"] > low_sent[\"t-1\"]].shape[0], low_sent[low_sent[\"Actual\"] < low_sent[\"t-1\"]].shape[0]))\n",
    "\n",
    "print(\"Equal-weighted price return (short lowest sentiment companies): {:.2f}\".format((low_sent[\"t-1\"] - low_sent[\"Actual\"]).sum()))\n",
    "\n",
    "tr = (top_sent[\"Actual\"] - top_sent[\"t-1\"]).sum() + (low_sent[\"t-1\"] - low_sent[\"Actual\"]).sum()\n",
    "print(\"Strategy: Long Top 20 Sentiment, Short Worst 20 Sentiment\")\n",
    "print(\"Net price return: {:.2f}\".format(tr))\n",
    "print(\"Net 1-day : {:.2f}%\\nAnnualized: {:.2f}%\".format(100 * tr / (top_sent[\"t-1\"].sum() + 1.5 * low_sent[\"t-1\"].sum()), (np.power(1 + tr / (top_sent[\"t-1\"].sum() + 1.5 * low_sent[\"t-1\"].sum()), 251) - 1) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
