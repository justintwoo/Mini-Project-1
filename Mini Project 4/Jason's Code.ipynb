{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# -- Sheet --\n",
    "\n",
    "import pandas as pd \n",
    "import re\n",
    "import os\n",
    "import string\n",
    "import csv\n",
    "import sys\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ticker                         created            id  polarity1 sentiment  \\\n",
      "0    MMM  Mon Apr 04 18:53:44 +0000 2022  1.510000e+18   0.106667  positive   \n",
      "1    MMM  Mon Apr 04 16:55:27 +0000 2022  1.510000e+18   0.000000   neutral   \n",
      "2    MMM  Mon Apr 04 16:00:46 +0000 2022  1.510000e+18   0.000000   neutral   \n",
      "3    MMM  Mon Apr 04 14:30:00 +0000 2022  1.510000e+18   0.000000   neutral   \n",
      "4    MMM  Fri Apr 01 14:48:13 +0000 2022  1.510000e+18   1.000000  positive   \n",
      "\n",
      "   subjectivity1  polarity2  subjectivity2  \n",
      "0       0.526667   0.106667       0.526667  \n",
      "1       0.000000   0.000000       0.000000  \n",
      "2       0.100000   0.000000       0.000000  \n",
      "3       0.000000   0.000000       0.000000  \n",
      "4       0.300000   1.000000       0.300000  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>-0.016707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AOS</td>\n",
       "      <td>-0.012981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABT</td>\n",
       "      <td>-0.007476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>-0.001954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABMD</td>\n",
       "      <td>-0.017808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker    change\n",
       "0    MMM -0.016707\n",
       "1    AOS -0.012981\n",
       "2    ABT -0.007476\n",
       "3   ABBV -0.001954\n",
       "4   ABMD -0.017808"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data = pd.read_csv(\"sentimenttweets.csv\")\n",
    "'''\n",
    "# tweet_data = pd.concat([pd.read_excel(os.path.join(\"twitterdata\", f), index_col = 0) for f in os.listdir(\"twitterdata\")])\n",
    "\n",
    "tweet_data = pd.read_csv(\"searchTweets.csv\")\n",
    "\n",
    "tweet_data = tweet_data[[\"ticker\", \"created\", \"sent_score\"]]\n",
    "\n",
    "tweet_data2 = tweet_data2[[\"ticker\", \"created\", \"sent_score\"]]\n",
    "\n",
    "tweet_data = pd.concat([tweet_data, tweet_data2], axis = 0)\n",
    "\n",
    "tweet_data.shape\n",
    "\n",
    "'''\n",
    "print(tweet_data.head())\n",
    "\n",
    "\n",
    "returns_data = pd.read_csv(\"stocks.csv\")\n",
    "\n",
    "returns_data.head()\n",
    "\n",
    "# returns_data.reset_index(inplace = True)\n",
    "\n",
    "# returns_data[\"Date\"] = pd.to_datetime(returns_data[\"Date\"]).dt.strftime(\"%m-%d-%Y\")\n",
    "\n",
    "# returns_data.rename(columns = {\"level_0\": \"ticker\", \"Date\": \"date\"}, inplace = True)\n",
    "\n",
    "# returns_data.set_index([\"ticker\", \"date\"], inplace = True, drop = True)\n",
    "\n",
    "# returns_data = returns_data[[\"Volume\", \"Adj Close\"]]\n",
    "\n",
    "# returns = returns_data[\"Adj Close\"].groupby(level = 0).apply(lambda x: x / x[1:4].max())\n",
    "# vol = returns_data.groupby(level = 0)[\"Volume\"].apply(lambda x: x / x[1:4].max())\n",
    "\n",
    "# returns_data = pd.concat([returns, vol], axis = 1)\n",
    "# returns_data.rename(columns = {\"Adj Close\": \"return\", \"Volume\": \"vol\"}, inplace = True)\n",
    "# returns_data.dropna(inplace = True)\n",
    "\n",
    "# tweet_data.rename(columns = {\"created\": \"date\"}, inplace = True)\n",
    "# tweet_data.set_index([\"ticker\", \"date\"], inplace = True, drop = True)\n",
    "\n",
    "# # Drop any tweets with 0 sentiment (irrelevant/couldn't be parsed/etc.)\n",
    "\n",
    "# tweet_data = tweet_data[tweet_data[\"sent_score\"] != 0]\n",
    "\n",
    "# # Calculate average sentiment score by date\n",
    "\n",
    "# tweet_sent_data = tweet_data.groupby([\"ticker\", \"date\"])[\"sent_score\"].agg(['mean', 'count'])\n",
    "# tweet_sent_data.columns = [\"sent_score\", \"tweet_volume\"]\n",
    "# tweet_sent_data[\"tweet_volume\"] = tweet_sent_data.groupby(level = 0)[\"tweet_volume\"].apply(lambda x: x / x[1:4].max())\n",
    "\n",
    "# combined_data = returns_data.merge(tweet_sent_data, left_index = True, right_index = True, how = \"left\")\n",
    "\n",
    "# # In case of companies that didn't have any Twitter data for a particular date... \n",
    "# combined_data.fillna(0, inplace = True)\n",
    "\n",
    "# dt = combined_data.reset_index()\n",
    "\n",
    "# dt[\"date\"] = pd.to_datetime(dt[\"date\"])\n",
    "# dt.set_index([\"ticker\", \"date\"], inplace = True, drop = True)\n",
    "# dt.sort_index(level = 1, ascending = False, inplace = True)\n",
    "\n",
    "# target = dt[dt.index.get_level_values(1) == '11-27-2020']\n",
    "# features = dt[dt.index.get_level_values(1) != '11-27-2020']\n",
    "\n",
    "# target = target[\"return\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>id</th>\n",
       "      <th>polarity1</th>\n",
       "      <th>subjectivity1</th>\n",
       "      <th>polarity2</th>\n",
       "      <th>subjectivity2</th>\n",
       "      <th>change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>1.510000e+18</td>\n",
       "      <td>0.137614</td>\n",
       "      <td>0.277176</td>\n",
       "      <td>0.132364</td>\n",
       "      <td>0.272676</td>\n",
       "      <td>-0.016241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAL</td>\n",
       "      <td>1.510000e+18</td>\n",
       "      <td>0.092037</td>\n",
       "      <td>0.243148</td>\n",
       "      <td>0.055926</td>\n",
       "      <td>0.273704</td>\n",
       "      <td>-0.011634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAP</td>\n",
       "      <td>1.510000e+18</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0.526667</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0.526667</td>\n",
       "      <td>-0.000425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>1.510000e+18</td>\n",
       "      <td>0.115024</td>\n",
       "      <td>0.333631</td>\n",
       "      <td>0.110274</td>\n",
       "      <td>0.360131</td>\n",
       "      <td>-0.015244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>1.510000e+18</td>\n",
       "      <td>0.287140</td>\n",
       "      <td>0.296502</td>\n",
       "      <td>0.287140</td>\n",
       "      <td>0.285391</td>\n",
       "      <td>-0.001954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>YUM</td>\n",
       "      <td>1.510000e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>ZBH</td>\n",
       "      <td>1.510000e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>ZBRA</td>\n",
       "      <td>1.510000e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>ZION</td>\n",
       "      <td>1.510000e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.028829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>1.510000e+18</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.108333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.014794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>374 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticker            id  polarity1  subjectivity1  polarity2  subjectivity2  \\\n",
       "0        A  1.510000e+18   0.137614       0.277176   0.132364       0.272676   \n",
       "1      AAL  1.510000e+18   0.092037       0.243148   0.055926       0.273704   \n",
       "2      AAP  1.510000e+18   0.106667       0.526667   0.106667       0.526667   \n",
       "3     AAPL  1.510000e+18   0.115024       0.333631   0.110274       0.360131   \n",
       "4     ABBV  1.510000e+18   0.287140       0.296502   0.287140       0.285391   \n",
       "..     ...           ...        ...            ...        ...            ...   \n",
       "369    YUM  1.510000e+18   0.000000       0.000000   0.000000       0.000000   \n",
       "370    ZBH  1.510000e+18   0.000000       0.000000   0.000000       0.000000   \n",
       "371   ZBRA  1.510000e+18   0.000000       0.000000   0.000000       0.000000   \n",
       "372   ZION  1.510000e+18   0.000000       0.000000   0.000000       0.000000   \n",
       "373    ZTS  1.510000e+18   0.133333       0.222222   0.108333       0.222222   \n",
       "\n",
       "       change  \n",
       "0   -0.016241  \n",
       "1   -0.011634  \n",
       "2   -0.000425  \n",
       "3   -0.015244  \n",
       "4   -0.001954  \n",
       "..        ...  \n",
       "369  0.000759  \n",
       "370 -0.000391  \n",
       "371  0.022238  \n",
       "372 -0.028829  \n",
       "373  0.014794  \n",
       "\n",
       "[374 rows x 7 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_agg = tweet_data.groupby(['ticker'],as_index=False).mean()\n",
    "pd_data = tweet_agg.merge(returns_data)\n",
    "pd_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent(row):\n",
    "    if row[2] > 0:\n",
    "        val = 'positive'\n",
    "    elif row[2] < 0:\n",
    "        val = 'negative'\n",
    "    else:\n",
    "        val = 'neutral'\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>polarity1</th>\n",
       "      <th>subjectivity1</th>\n",
       "      <th>polarity2</th>\n",
       "      <th>subjectivity2</th>\n",
       "      <th>change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>1.510000e+18</td>\n",
       "      <td>-0.07662</td>\n",
       "      <td>0.219143</td>\n",
       "      <td>-0.076697</td>\n",
       "      <td>0.218786</td>\n",
       "      <td>-0.019299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>1.510000e+18</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.057030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057030</td>\n",
       "      <td>-0.011976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>1.510000e+18</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0.308270</td>\n",
       "      <td>0.164174</td>\n",
       "      <td>0.309364</td>\n",
       "      <td>-0.015691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id  polarity1  subjectivity1  polarity2  subjectivity2  \\\n",
       "sentiment                                                                     \n",
       "negative   1.510000e+18   -0.07662       0.219143  -0.076697       0.218786   \n",
       "neutral    1.510000e+18    0.00000       0.057030   0.000000       0.057030   \n",
       "positive   1.510000e+18    0.17300       0.308270   0.164174       0.309364   \n",
       "\n",
       "             change  \n",
       "sentiment            \n",
       "negative  -0.019299  \n",
       "neutral   -0.011976  \n",
       "positive  -0.015691  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_data['sentiment'] = pd_data.apply(get_sent, axis=1)\n",
    "pd_data.groupby(['sentiment']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['polarity', 'subjectivity'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cq/09tgzz4968j9k4kbntx0mmrh0000gn/T/ipykernel_59765/457906536.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'change'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'polarity'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'subjectivity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3462\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3463\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3464\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3466\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis)\u001b[0m\n\u001b[1;32m   1372\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['polarity', 'subjectivity'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "target = pd_data['change']\n",
    "features = pd_data[['polarity','subjectivity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state = 0, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model = model.fit(X_train, y_train)\n",
    "\n",
    "prediction = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, prediction)\n",
    "r2 = r2_score(y_test, prediction)\n",
    "\n",
    "print(\"\\nThe model performance for training set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('MSE is {}'.format(mse))\n",
    "print('R2 is {}'.format(r2))\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Regression\n",
    "knn = KNeighborsRegressor()\n",
    "neighbors = list(range(1,51))\n",
    "\n",
    "param_grid = dict(n_neighbors = neighbors)\n",
    "knn_grid = GridSearchCV(knn, param_grid, cv=10)\n",
    "\n",
    "knn_grid.fit(features, target)\n",
    "y_pred = list(knn_grid.predict(features))\n",
    "knn_grid.score(features, target) \n",
    "knn_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphing the MSE for each hyperparameter\n",
    "error = []\n",
    "for k in range(1,51):\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    y_pred = cross_val_predict(knn, features, target, cv=5)\n",
    "    error.append(mean_squared_error(target,y_pred))\n",
    "plt.plot(range(1,51),error)\n",
    "plt.xlabel('K nearest neighbors')\n",
    "plt.ylabel('Mean Squared Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "train_tickers = list(random.sample(list(dt.index.get_level_values(0).unique()), 400))\n",
    "test_tickers = [x for x in dt.index.get_level_values(0).unique() if x not in train_tickers]\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "X_train = np.array([features[features.index.get_level_values(0) == ticker].values.tolist() for ticker in train_tickers])\n",
    "y_train = np.array([target[target.index.get_level_values(0) == ticker].values.tolist() for ticker in train_tickers])\n",
    "\n",
    "X_test = np.array([features[features.index.get_level_values(0) == ticker].values.tolist() for ticker in test_tickers])\n",
    "y_test = np.array([target[target.index.get_level_values(0) == ticker].values.tolist() for ticker in test_tickers])\n",
    "\n",
    "X_test[1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(units = 10, return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "# model.add(LSTM(units = 5))\n",
    "# model.add(Dense(units = 1))\n",
    "\n",
    "# early_stop = EarlyStopping(monitor='loss', patience=10, verbose=1)\n",
    "\n",
    "# model.compile(optimizer = \"adam\", loss = \"mean_squared_error\")\n",
    "\n",
    "# model.fit(X_train, y_train, epochs = 50, batch_size = 30, callbacks=[early_stop])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# y_test_pred = model.predict(X_test)\n",
    "\n",
    "# y_test_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.scatter(y_test, y_test_pred)\n",
    "# plt.show()\n",
    "\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "# preds = pd.DataFrame({\"Predicted\": y_test_pred.flatten(), \"Actual\": y_test.flatten()})\n",
    "# preds.plot()\n",
    "\n",
    "# results = pd.DataFrame({\"Predicted\": y_test_pred.flatten(), \"Actual\": y_test.flatten()}, index = test_tickers)\n",
    "\n",
    "# results.head()\n",
    "\n",
    "# t_0 = features[features.index.get_level_values(1) == '11/25/2020'][[\"return\", \"sent_score\"]].reset_index(level = 1)\n",
    "\n",
    "# res = results.merge(t_0, how = \"left\", left_index = True, right_index = True)\n",
    "\n",
    "# res.rename(columns = {\"return\": \"t-1\"}, inplace = True)\n",
    "# res.drop(columns = [\"date\"], inplace = True)\n",
    "\n",
    "# res.head()\n",
    "\n",
    "# ups = res[res[\"Predicted\"] > res[\"t-1\"]]\n",
    "\n",
    "# downs = res[res[\"Predicted\"] < res[\"t-1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(\"Ups: {} Downs: {}\".format(ups.shape[0], downs.shape[0]))\n",
    "\n",
    "# print(\"Out of {} predicted ups, {} actually went up\".format(ups.shape[0], res[(res[\"Predicted\"] > res[\"t-1\"]) & (res[\"Actual\"] > res[\"t-1\"])].shape[0]))\n",
    "\n",
    "# print(\"Out of {} predicted downs, {} actually went down\".format(downs.shape[0], res[(res[\"Predicted\"] < res[\"t-1\"]) & (res[\"Actual\"] < res[\"t-1\"])].shape[0]))\n",
    "\n",
    "# abs_up_ret = (ups[\"Actual\"] - ups[\"t-1\"]).sum()\n",
    "# print(\"If we bought equally-weighted shares of each predicted up, we would have made: {:.2f}\".format(abs_up_ret))\n",
    "# print(\"Of a total investment of {:.2f}, that's a 1-day return of {:.2f}%\".format(ups[\"t-1\"].sum(), abs_up_ret / ups[\"t-1\"].sum() * 100))\n",
    "# print(\"Annualized, that figure is {:.2f}%\".format((np.power(1 + abs_up_ret / ups[\"t-1\"].sum(), 251) - 1) * 100))\n",
    "\n",
    "# abs_down_ret = (downs[\"t-1\"] - downs[\"Actual\"]).sum()\n",
    "# print(\"If we shorted equally-weighted shares of each predicted down, we would have made: {:.2f}\".format(abs_down_ret))\n",
    "# print(\"Of a total investment of {:.2f} (@150% margin), that's a 1-day return of {:.2f}%\".format(downs[\"t-1\"].sum() * 1.5, abs_down_ret / (downs[\"t-1\"].sum() * 1.5) * 100))\n",
    "# print(\"Annualized, that figure is {:.2f}%\".format((np.power(1 + abs_down_ret / (downs[\"t-1\"].sum() * 1.5), 251) - 1) * 100))\n",
    "\n",
    "# # Impact of sentiment on performance\n",
    "\n",
    "# top_sent = res.nlargest(20, columns = \"sent_score\")\n",
    "# low_sent = res.nsmallest(20, columns = \"sent_score\")\n",
    "\n",
    "# print(\"Of 20 companies with highest sentiment at t-1, {} went up, {} went down\".format(top_sent[top_sent[\"Actual\"] > top_sent[\"t-1\"]].shape[0], top_sent[top_sent[\"Actual\"] < top_sent[\"t-1\"]].shape[0]))\n",
    "\n",
    "# print(\"Equal-weighted price return (long highest sentiment companies): {:.2f}\".format((top_sent[\"Actual\"] - top_sent[\"t-1\"]).sum()))\n",
    "\n",
    "# print(\"Of 20 companies with lowest sentiment at t-1, {} went up, {} went down\".format(low_sent[low_sent[\"Actual\"] > low_sent[\"t-1\"]].shape[0], low_sent[low_sent[\"Actual\"] < low_sent[\"t-1\"]].shape[0]))\n",
    "\n",
    "# print(\"Equal-weighted price return (short lowest sentiment companies): {:.2f}\".format((low_sent[\"t-1\"] - low_sent[\"Actual\"]).sum()))\n",
    "\n",
    "# tr = (top_sent[\"Actual\"] - top_sent[\"t-1\"]).sum() + (low_sent[\"t-1\"] - low_sent[\"Actual\"]).sum()\n",
    "# print(\"Strategy: Long Top 20 Sentiment, Short Worst 20 Sentiment\")\n",
    "# print(\"Net price return: {:.2f}\".format(tr))\n",
    "# print(\"Net 1-day : {:.2f}%\\nAnnualized: {:.2f}%\".format(100 * tr / (top_sent[\"t-1\"].sum() + 1.5 * low_sent[\"t-1\"].sum()), (np.power(1 + tr / (top_sent[\"t-1\"].sum() + 1.5 * low_sent[\"t-1\"].sum()), 251) - 1) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
