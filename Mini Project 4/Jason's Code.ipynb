{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# -- Sheet --\n",
    "\n",
    "import pandas as pd \n",
    "import re\n",
    "import os\n",
    "import string\n",
    "import csv\n",
    "import sys\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ticker                         created            id  sent_score sentiment\n",
      "0    MMM  Thu Mar 31 22:51:05 +0000 2022  1.510000e+18    1.000000  positive\n",
      "1    MMM  Thu Mar 31 22:30:02 +0000 2022  1.510000e+18    0.275000  positive\n",
      "2    MMM  Thu Mar 31 20:28:37 +0000 2022  1.510000e+18    0.106667  positive\n",
      "3    MMM  Thu Mar 31 17:33:06 +0000 2022  1.510000e+18    1.000000  positive\n",
      "4    MMM  Tue Mar 29 23:03:05 +0000 2022  1.510000e+18    1.000000  positive\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticker</th>\n",
       "      <th>change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MMM</th>\n",
       "      <th>0.012653</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AOS</th>\n",
       "      <th>-0.013987</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABT</th>\n",
       "      <th>-0.023078</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABBV</th>\n",
       "      <th>0.007997</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABMD</th>\n",
       "      <th>0.039578</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [(MMM, 0.012653149), (AOS, -0.013986999), (ABT, -0.023078229), (ABBV, 0.007997493), (ABMD, 0.039577541)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data = pd.read_csv(\"sentimenttweets.csv\")\n",
    "'''\n",
    "# tweet_data = pd.concat([pd.read_excel(os.path.join(\"twitterdata\", f), index_col = 0) for f in os.listdir(\"twitterdata\")])\n",
    "\n",
    "tweet_data = pd.read_csv(\"searchTweets.csv\")\n",
    "\n",
    "tweet_data = tweet_data[[\"ticker\", \"created\", \"sent_score\"]]\n",
    "\n",
    "tweet_data2 = tweet_data2[[\"ticker\", \"created\", \"sent_score\"]]\n",
    "\n",
    "tweet_data = pd.concat([tweet_data, tweet_data2], axis = 0)\n",
    "\n",
    "tweet_data.shape\n",
    "\n",
    "'''\n",
    "print(tweet_data.head())\n",
    "\n",
    "\n",
    "returns_data = pd.read_csv(\"stocks.csv\", index_col = (0, 1))\n",
    "\n",
    "returns_data.head()\n",
    "\n",
    "# returns_data.reset_index(inplace = True)\n",
    "\n",
    "# returns_data[\"Date\"] = pd.to_datetime(returns_data[\"Date\"]).dt.strftime(\"%m-%d-%Y\")\n",
    "\n",
    "# returns_data.rename(columns = {\"level_0\": \"ticker\", \"Date\": \"date\"}, inplace = True)\n",
    "\n",
    "# returns_data.set_index([\"ticker\", \"date\"], inplace = True, drop = True)\n",
    "\n",
    "# returns_data = returns_data[[\"Volume\", \"Adj Close\"]]\n",
    "\n",
    "# returns = returns_data[\"Adj Close\"].groupby(level = 0).apply(lambda x: x / x[1:4].max())\n",
    "# vol = returns_data.groupby(level = 0)[\"Volume\"].apply(lambda x: x / x[1:4].max())\n",
    "\n",
    "# returns_data = pd.concat([returns, vol], axis = 1)\n",
    "# returns_data.rename(columns = {\"Adj Close\": \"return\", \"Volume\": \"vol\"}, inplace = True)\n",
    "# returns_data.dropna(inplace = True)\n",
    "\n",
    "# tweet_data.rename(columns = {\"created\": \"date\"}, inplace = True)\n",
    "# tweet_data.set_index([\"ticker\", \"date\"], inplace = True, drop = True)\n",
    "\n",
    "# # Drop any tweets with 0 sentiment (irrelevant/couldn't be parsed/etc.)\n",
    "\n",
    "# tweet_data = tweet_data[tweet_data[\"sent_score\"] != 0]\n",
    "\n",
    "# # Calculate average sentiment score by date\n",
    "\n",
    "# tweet_sent_data = tweet_data.groupby([\"ticker\", \"date\"])[\"sent_score\"].agg(['mean', 'count'])\n",
    "# tweet_sent_data.columns = [\"sent_score\", \"tweet_volume\"]\n",
    "# tweet_sent_data[\"tweet_volume\"] = tweet_sent_data.groupby(level = 0)[\"tweet_volume\"].apply(lambda x: x / x[1:4].max())\n",
    "\n",
    "# combined_data = returns_data.merge(tweet_sent_data, left_index = True, right_index = True, how = \"left\")\n",
    "\n",
    "# # In case of companies that didn't have any Twitter data for a particular date... \n",
    "# combined_data.fillna(0, inplace = True)\n",
    "\n",
    "# dt = combined_data.reset_index()\n",
    "\n",
    "# dt[\"date\"] = pd.to_datetime(dt[\"date\"])\n",
    "# dt.set_index([\"ticker\", \"date\"], inplace = True, drop = True)\n",
    "# dt.sort_index(level = 1, ascending = False, inplace = True)\n",
    "\n",
    "# target = dt[dt.index.get_level_values(1) == '11-27-2020']\n",
    "# features = dt[dt.index.get_level_values(1) != '11-27-2020']\n",
    "\n",
    "# target = target[\"return\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cat_features, target, random_state = 0, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "train_tickers = list(random.sample(list(dt.index.get_level_values(0).unique()), 400))\n",
    "test_tickers = [x for x in dt.index.get_level_values(0).unique() if x not in train_tickers]\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "X_train = np.array([features[features.index.get_level_values(0) == ticker].values.tolist() for ticker in train_tickers])\n",
    "y_train = np.array([target[target.index.get_level_values(0) == ticker].values.tolist() for ticker in train_tickers])\n",
    "\n",
    "X_test = np.array([features[features.index.get_level_values(0) == ticker].values.tolist() for ticker in test_tickers])\n",
    "y_test = np.array([target[target.index.get_level_values(0) == ticker].values.tolist() for ticker in test_tickers])\n",
    "\n",
    "X_test[1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units = 10, return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "model.add(LSTM(units = 5))\n",
    "model.add(Dense(units = 1))\n",
    "\n",
    "early_stop = EarlyStopping(monitor='loss', patience=10, verbose=1)\n",
    "\n",
    "model.compile(optimizer = \"adam\", loss = \"mean_squared_error\")\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 50, batch_size = 30, callbacks=[early_stop])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "y_test_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(y_test, y_test_pred)\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "preds = pd.DataFrame({\"Predicted\": y_test_pred.flatten(), \"Actual\": y_test.flatten()})\n",
    "preds.plot()\n",
    "\n",
    "results = pd.DataFrame({\"Predicted\": y_test_pred.flatten(), \"Actual\": y_test.flatten()}, index = test_tickers)\n",
    "\n",
    "results.head()\n",
    "\n",
    "t_0 = features[features.index.get_level_values(1) == '11/25/2020'][[\"return\", \"sent_score\"]].reset_index(level = 1)\n",
    "\n",
    "res = results.merge(t_0, how = \"left\", left_index = True, right_index = True)\n",
    "\n",
    "res.rename(columns = {\"return\": \"t-1\"}, inplace = True)\n",
    "res.drop(columns = [\"date\"], inplace = True)\n",
    "\n",
    "res.head()\n",
    "\n",
    "ups = res[res[\"Predicted\"] > res[\"t-1\"]]\n",
    "\n",
    "downs = res[res[\"Predicted\"] < res[\"t-1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Ups: {} Downs: {}\".format(ups.shape[0], downs.shape[0]))\n",
    "\n",
    "print(\"Out of {} predicted ups, {} actually went up\".format(ups.shape[0], res[(res[\"Predicted\"] > res[\"t-1\"]) & (res[\"Actual\"] > res[\"t-1\"])].shape[0]))\n",
    "\n",
    "print(\"Out of {} predicted downs, {} actually went down\".format(downs.shape[0], res[(res[\"Predicted\"] < res[\"t-1\"]) & (res[\"Actual\"] < res[\"t-1\"])].shape[0]))\n",
    "\n",
    "abs_up_ret = (ups[\"Actual\"] - ups[\"t-1\"]).sum()\n",
    "print(\"If we bought equally-weighted shares of each predicted up, we would have made: {:.2f}\".format(abs_up_ret))\n",
    "print(\"Of a total investment of {:.2f}, that's a 1-day return of {:.2f}%\".format(ups[\"t-1\"].sum(), abs_up_ret / ups[\"t-1\"].sum() * 100))\n",
    "print(\"Annualized, that figure is {:.2f}%\".format((np.power(1 + abs_up_ret / ups[\"t-1\"].sum(), 251) - 1) * 100))\n",
    "\n",
    "abs_down_ret = (downs[\"t-1\"] - downs[\"Actual\"]).sum()\n",
    "print(\"If we shorted equally-weighted shares of each predicted down, we would have made: {:.2f}\".format(abs_down_ret))\n",
    "print(\"Of a total investment of {:.2f} (@150% margin), that's a 1-day return of {:.2f}%\".format(downs[\"t-1\"].sum() * 1.5, abs_down_ret / (downs[\"t-1\"].sum() * 1.5) * 100))\n",
    "print(\"Annualized, that figure is {:.2f}%\".format((np.power(1 + abs_down_ret / (downs[\"t-1\"].sum() * 1.5), 251) - 1) * 100))\n",
    "\n",
    "# Impact of sentiment on performance\n",
    "\n",
    "top_sent = res.nlargest(20, columns = \"sent_score\")\n",
    "low_sent = res.nsmallest(20, columns = \"sent_score\")\n",
    "\n",
    "print(\"Of 20 companies with highest sentiment at t-1, {} went up, {} went down\".format(top_sent[top_sent[\"Actual\"] > top_sent[\"t-1\"]].shape[0], top_sent[top_sent[\"Actual\"] < top_sent[\"t-1\"]].shape[0]))\n",
    "\n",
    "print(\"Equal-weighted price return (long highest sentiment companies): {:.2f}\".format((top_sent[\"Actual\"] - top_sent[\"t-1\"]).sum()))\n",
    "\n",
    "print(\"Of 20 companies with lowest sentiment at t-1, {} went up, {} went down\".format(low_sent[low_sent[\"Actual\"] > low_sent[\"t-1\"]].shape[0], low_sent[low_sent[\"Actual\"] < low_sent[\"t-1\"]].shape[0]))\n",
    "\n",
    "print(\"Equal-weighted price return (short lowest sentiment companies): {:.2f}\".format((low_sent[\"t-1\"] - low_sent[\"Actual\"]).sum()))\n",
    "\n",
    "tr = (top_sent[\"Actual\"] - top_sent[\"t-1\"]).sum() + (low_sent[\"t-1\"] - low_sent[\"Actual\"]).sum()\n",
    "print(\"Strategy: Long Top 20 Sentiment, Short Worst 20 Sentiment\")\n",
    "print(\"Net price return: {:.2f}\".format(tr))\n",
    "print(\"Net 1-day : {:.2f}%\\nAnnualized: {:.2f}%\".format(100 * tr / (top_sent[\"t-1\"].sum() + 1.5 * low_sent[\"t-1\"].sum()), (np.power(1 + tr / (top_sent[\"t-1\"].sum() + 1.5 * low_sent[\"t-1\"].sum()), 251) - 1) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
