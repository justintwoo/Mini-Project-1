{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "import re\n",
    "import string\n",
    "from textblob import TextBlob\n",
    "import preprocessor as p\n",
    "import csv\n",
    "import sys\n",
    "import pandas_datareader as pdr\n",
    "import datetime\n",
    "from nltk.corpus import stopwords\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-03-30</th>\n",
       "      <td>153.259995</td>\n",
       "      <td>150.770004</td>\n",
       "      <td>151.330002</td>\n",
       "      <td>151.429993</td>\n",
       "      <td>2395100</td>\n",
       "      <td>151.429993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-31</th>\n",
       "      <td>151.250000</td>\n",
       "      <td>148.800003</td>\n",
       "      <td>150.449997</td>\n",
       "      <td>148.880005</td>\n",
       "      <td>3193800</td>\n",
       "      <td>148.880005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-01</th>\n",
       "      <td>149.860001</td>\n",
       "      <td>146.850006</td>\n",
       "      <td>149.630005</td>\n",
       "      <td>149.690002</td>\n",
       "      <td>2196400</td>\n",
       "      <td>149.690002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-04</th>\n",
       "      <td>150.009995</td>\n",
       "      <td>146.080002</td>\n",
       "      <td>149.059998</td>\n",
       "      <td>149.529999</td>\n",
       "      <td>2631800</td>\n",
       "      <td>149.529999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-05</th>\n",
       "      <td>150.630005</td>\n",
       "      <td>148.509995</td>\n",
       "      <td>148.649994</td>\n",
       "      <td>148.899994</td>\n",
       "      <td>2148600</td>\n",
       "      <td>148.899994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  High         Low        Open       Close   Volume  \\\n",
       "Date                                                                  \n",
       "2022-03-30  153.259995  150.770004  151.330002  151.429993  2395100   \n",
       "2022-03-31  151.250000  148.800003  150.449997  148.880005  3193800   \n",
       "2022-04-01  149.860001  146.850006  149.630005  149.690002  2196400   \n",
       "2022-04-04  150.009995  146.080002  149.059998  149.529999  2631800   \n",
       "2022-04-05  150.630005  148.509995  148.649994  148.899994  2148600   \n",
       "\n",
       "             Adj Close  \n",
       "Date                    \n",
       "2022-03-30  151.429993  \n",
       "2022-03-31  148.880005  \n",
       "2022-04-01  149.690002  \n",
       "2022-04-04  149.529999  \n",
       "2022-04-05  148.899994  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startdate = datetime.datetime(2022,3,30)\n",
    "enddate = datetime.datetime(2022,4,5)\n",
    "st = pdr.get_data_yahoo('MMM',start=startdate,end=enddate)\n",
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected parameter: since\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tweepy.cursor.ItemIterator object at 0x7fc1f2984e50>\n",
      "Thu Mar 31 22:51:05 +0000 2022\n",
      "Thu Mar 31 22:30:02 +0000 2022\n",
      "Thu Mar 31 20:28:37 +0000 2022\n",
      "Thu Mar 31 17:33:06 +0000 2022\n",
      "Tue Mar 29 23:03:05 +0000 2022\n"
     ]
    }
   ],
   "source": [
    "# Get Twitter data and do sentiment analysis\n",
    "# Authenticate credentials\n",
    "\n",
    "#Twitter credentials for the app\n",
    "consumer_key = 'aR8jQP7cfr623h9apTvM711pm'\n",
    "consumer_secret = 'SLKF8TOUL8PtapZ5amz4Y9ZBRE99ocRxwvEnzIjfEFri2TbhTI'\n",
    "access_key= '1511751059332493317-eFiU4zDgdWqZPDC7EWZrQVaCLJ5ZX8'\n",
    "access_secret = 'U3yAxDcXSFVHqsbJW1adpZiElFoIBosY7FW1UJpAOULqM'\n",
    "\n",
    "#Pass twitter credentials to tweepy\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key,access_secret)\n",
    "# api = tweepy.API(auth, wait_on_rate_limit = True, wait_on_rate_limit_notify=True)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "query = \"$\"+\"MMM\" + \" -filter:retweets -filter:replies\"\n",
    "tweets = tweepy.Cursor(api.search_tweets ,q=query,lang='en', since = startdate, until = enddate, tweet_mode='extended').items(5)\n",
    "print(tweets)\n",
    "for tweet in tweets:\n",
    "    status=tweet._json\n",
    "    created_at = status['created_at']\n",
    "    tweet_id = status['id_str']\n",
    "    tweet_text = status['full_text']\n",
    "    tweet_text = re.sub(r'\\W', ' ',tweet_text)\n",
    "    print(created_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain stock tickers\n",
    "\n",
    "data = pd.read_html('https://en.wikipedia.org/wiki/List_of_S&P_500_companies')\n",
    "#print(data)\n",
    "table = data[0]\n",
    "#table.head()\n",
    "tickers = table['Symbol'].tolist()\n",
    "tickers1 = tickers[:49]\n",
    "tickers2 = tickers[49:99]\n",
    "tickers3 = tickers[99:149]\n",
    "tickers4 = tickers[149:199]\n",
    "tickers5 = tickers[199:249]\n",
    "tickers6 = tickers[249:299]\n",
    "tickers7 = tickers[349:399]\n",
    "tickers8 = tickers[449:490]\n",
    "tickers9 = tickers[480:500]\n",
    "tickers10 = tickers[500:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n"
     ]
    }
   ],
   "source": [
    "# Get stock prices and returns\n",
    "startdate = datetime.datetime(2022,3,30)\n",
    "enddate = datetime.datetime(2022,4,5)\n",
    "\n",
    "file = open(\"stocks.csv\",'w',newline='')\n",
    "print(len(tickers))\n",
    "count = 0\n",
    "for ticker in tickers:\n",
    "    count +=1\n",
    "    print(count)\n",
    "    try:\n",
    "        st = pdr.get_data_yahoo(ticker,start=startdate,end=enddate)\n",
    "        st['pct_change'] = st['Adj Close'].pct_change(4)\n",
    "        #print(ticker + str(st['Adj Close']) + str(st['pct_change']))\n",
    "        stockdata = csv.writer(file)\n",
    "        stockdata.writerow([ticker,st['pct_change'].iloc[-1]])\n",
    "    except:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Oversold on Hourly   https   t co 2Hf0ZbjpKC   HIG  73 98  to 72 80   T  24 14  to 23 82   CTXS  101 49  to 101 13   YUM  122 31  to 119 77   LULU  377 00  to 369 74   BYND  50 18  to 48 50\n",
      "Oversold on Hourly   https   t co 2Hf0ZbjpKC   HIG  73 98  to 72 80   T  24 14  to 23 82   CTXS  101 49  to 101 13   XLI  104 96  to 104 02   YUM  122 31  to 119 77   LULU  377 00  to 369 74   BYND  50 18  to 48 50\n",
      "Oversold on Hourly   https   t co 2Hf0ZbjpKC   HIG  73 98  to 72 80   T  24 14  to 23 82   CTXS  101 49  to 101 13   XLI  104 96  to 104 02   YUM  122 31  to 119 77   LULU  377 00  to 369 74   BYND  50 18  to 48 50   GT  14 6\n",
      "2\n",
      "   ZBRA price target update    Upgraded by JPMorgan Chase  amp  Co  From  530 00 to  500 00  Day quote change   435  5 24   Target upside  14 94   Published  April 4  2022 https   t co 5m2UMVLJdS\n",
      "   ZBRA price target update    Upgraded by JPMorgan Chase  amp  Co  From  530 00 to  500 00  Day quote change   429 92  4 01   Target upside  16 3   Published  April 4  2022 https   t co 5m2UMVLJdS\n",
      "S amp P500上昇率上位 Twitter  TWTR21 62  Zebra Technologies  ZBRA 3 40  ServiceNow  NOW 3 26  Penn National Gaming  PENN 3 00  Caesars Entertainment  CZR 2 88  SolarEdge   SEDG 2 84  IPG Photonics  IPGP 2 84  salesforce   CRM 2 72  Enphase Energy  ENPH 2 72  Ceridian HCM  CDAY 2 54 \n",
      "3\n",
      "   ZBH price target update    Downgraded by Citigroup From  125 15 to  135 00  Day quote change   113 96   0 13   Target upside  18 46   Published  April 1  2022 https   t co meqdRuYV52\n",
      "   ZBH price target update    Downgraded by Citigroup From  125 15 to  135 00  Day quote change   126 02   1 45   Target upside  7 13   Published  April 1  2022 https   t co meqdRuYV52\n",
      " ZBH Max Pain is 120 00 for maturity 04 14 2022   maxpain  options https   t co Y1g39bK2cB https   t co vkGTLgeGyw\n",
      " ZBH Max Pain is 120 00 for maturity 04 14 2022   maxpain  options https   t co Y1g39bK2cB https   t co XPEc1bMH97\n",
      "4\n",
      "   ZION price target update    Target Raised by The Goldman Sachs Group From  70 00 to  78 00  Day quote change   64 19   0 16   Target upside  21 51   Published  April 4  2022 https   t co KXHx0L0hVX\n",
      "   ZION price target update    Target Raised by The Goldman Sachs Group From  70 00 to  78 00  Day quote change   63 73   0 83   Target upside  22 39   Published  April 4  2022 https   t co KXHx0L0hVX\n",
      "5\n",
      " ZTS Max Pain is 200 00 for maturity 04 14 2022   maxpain  options https   t co sl1yMY4x20 https   t co GWccehUuGp\n",
      "Nice print for  ZTS Size  141000 Price  192 45 Amount   27 135 450 00 Time  956 See more  https   t co 6H1nzUqwma Join https   t co JWvlYbvmfL to get REAL TIME prints  Runners    https   t co VC1LdPYLBp Losers    https   t co 9MWV4TYQ9o Gappers    https   t co bHQKF2dERV\n",
      " ZTS  15s  delayed   Issued Press Release on March 31  08 30 00  Zoetis to Host Webcast and Conference Call on First Quarter 2022 Financial Results https   t co xoqzgKzdvo\n"
     ]
    }
   ],
   "source": [
    "# Get Twitter data and do sentiment analysis\n",
    "# Authenticate credentials\n",
    "\n",
    "#Twitter credentials for the app\n",
    "# consumer_key = 'ELRou1VKpS5p7EBEGamXqqGRT'\n",
    "# consumer_secret = 'QbsToHJOyA9ZsDrFCCw1aErF9LubwqlfLpLcJviruhKepQwX3D'\n",
    "# access_key= '3138259520-6jOClvoHXzF5DCf2XaylTxhrn1Rb7X50ykQyU3C'\n",
    "# access_secret = 'r9bokM5UvRbS8QnsYdQksSi2tO8gRj7T4sfq2K41jzmQM'\n",
    "\n",
    "# consumer_key = 'aR8jQP7cfr623h9apTvM711pm'\n",
    "# consumer_secret = 'SLKF8TOUL8PtapZ5amz4Y9ZBRE99ocRxwvEnzIjfEFri2TbhTI'\n",
    "# access_key= '1511751059332493317-eFiU4zDgdWqZPDC7EWZrQVaCLJ5ZX8'\n",
    "# access_secret = 'U3yAxDcXSFVHqsbJW1adpZiElFoIBosY7FW1UJpAOULqM'\n",
    "\n",
    "# consumer_key = 'Rd9nlZE2GWgkXXj6LfCGnWCtq'\n",
    "# consumer_secret = 'yCQeUkiwCUtgsvdn46jQiK6yqISlXy8xlbV3PG4rr8sb3qgWpZ'\n",
    "# access_key= '1432859916277063683-ZAXekHTSaIi3IecnfXAAlR1iCDWEO6'\n",
    "# access_secret = 'LtxEkUYYuuRAePwCJaDhexTa2KwKn8nem26SZSHsfc2bu'\n",
    "\n",
    "consumer_key = 'lLoOz2cbplDwX3vTzZFv2Hyqz'\n",
    "consumer_secret = 'Yp5YFPvY3ISI2KUVQC6HAqYjDCUWw5na3IFrCvTVoTuvF9QddN'\n",
    "access_key= '3028339548-i1TWGaqfItqlybCtkJZUQ7km95pylMZl8zPQBLb'\n",
    "access_secret = 'llC8DaUitlD5wMl0FMqSxR3L78q0OaF56oazKJF5Hqnnr'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Pass twitter credentials to tweepy\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key,access_secret)\n",
    "# api = tweepy.API(auth, wait_on_rate_limit = True, wait_on_rate_limit_notify=True)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "file = open(\"searchTweets10.csv\",\"w\",newline='')\n",
    "alltweets = csv.writer(file)\n",
    "count = 0\n",
    "for ticker in tickers10:\n",
    "    count += 1\n",
    "    print(count)\n",
    "    query = \"$\"+ticker + \" -filter:retweets -filter:replies\"\n",
    "    tweets = tweepy.Cursor(api.search_tweets ,q=query,lang='en', until = enddate, tweet_mode='extended').items(20)\n",
    "    for tweet in tweets:\n",
    "        status=tweet._json\n",
    "        created_at = status['created_at']\n",
    "        tweet_id = status['id_str']\n",
    "        tweet_text = status['full_text']\n",
    "        tweet_text = re.sub(r'\\W', ' ',tweet_text)\n",
    "        print(tweet_text)\n",
    "        try: \n",
    "            alltweets.writerow([ticker,created_at,tweet_id, tweet_text])\n",
    "        except UnicodeEncodeError:\n",
    "            pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MMM open interest maturity 04 08 2022 High put 145 00 High call 152 50 PutCallRatio 0 91 maxpain option http co aHXahUSCdG http co cmojteFgiv'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text Processing\n",
    "\n",
    "# Open tweets CSV\n",
    "file = open(\"searchTweets.csv\",\"r\")\n",
    "tweets = pd.read_csv(file)\n",
    "\n",
    "# Import stopwords with nltk.\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "# Exclude stopwords with Python's list comprehension and pandas.DataFrame.apply.\n",
    "tweets['tweet_without_stopwords'] = tweets['tweet'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "# Text Normalization\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    words = [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "    return \" \".join(words)\n",
    "tweets['processed_tweet'] = tweets.tweet_without_stopwords.apply(lemmatize_text)\n",
    "\n",
    "\n",
    "tweets[['processed_tweet']].values[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_csv.reader object at 0x1280f7e40>\n"
     ]
    }
   ],
   "source": [
    "# Sentiment analysis\n",
    "\n",
    "file = open(\"searchTweets.csv\",\"r\")\n",
    "alltweets = csv.reader(file)\n",
    "print(alltweets)\n",
    "sentiment_file = open(\"sentimenttweets.csv\",\"w\",newline='')\n",
    "sntTweets=csv.writer(sentiment_file)\n",
    "count = 0\n",
    "for row in alltweets:\n",
    "    processed_tweet = tweets[['processed_tweet']].values[count][0]\n",
    "    blob = TextBlob(row[3])\n",
    "    blob2 = TextBlob(processed_tweet)\n",
    "    if blob2.sentiment.polarity>0:\n",
    "        sntTweets.writerow([row[0],row[1],row[2],blob.sentiment.polarity,\"positive\", blob.sentiment.subjectivity, blob2.sentiment.polarity, blob2.subjectivity])\n",
    "    elif blob2.sentiment.polarity<0:\n",
    "        sntTweets.writerow([row[0],row[1],row[2],blob.sentiment.polarity,\"negative\", blob.sentiment.subjectivity, blob2.sentiment.polarity, blob2.subjectivity])    \n",
    "    elif blob2.sentiment.polarity==0:\n",
    "        sntTweets.writerow([row[0],row[1],row[2],blob.sentiment.polarity,\"neutral\", blob.sentiment.subjectivity, blob2.sentiment.polarity, blob2.subjectivity])\n",
    "    count += 1\n",
    "        \n",
    "file.close()\n",
    "sentiment_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
