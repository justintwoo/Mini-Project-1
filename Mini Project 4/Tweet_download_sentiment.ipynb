{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tweepy\n",
    "#!pip install preprocessor\n",
    "#!pip install textblob\n",
    "import os\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "import re\n",
    "import string\n",
    "\n",
    "import preprocessor as p\n",
    "import csv\n",
    "import sys\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords') \n",
    "nltk.download('punkt')\n",
    "#from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MentorWorks  team has been working remotely for more than a week now  amp  we re trying different things to stay connected to each other  virtual coffee chats  lunches and happy hours via  zoom   We re looking for other ideas too   what are you doing  XrTerra  amp   StackEducation  \n",
      "RT  XrTerra  Shoutout to  BostonVRMeetup for making it onto this list  We re proud to be a part of the movement to make  Boston the nationa \n",
      "Happy  InternationalWomensDay to all the women making a difference in our world  today and always    InternationalWomenDay2020  InternationalWomensDay2020\n",
      "RT  AGBenoit  Tip for success  listen with your ears  amp  eyes to learn the professional skills for success  Get  BFITinvolved  blackhistorymo \n",
      "RT  BFITinvolved  During our final event of  BlackHistoryMonth  we welcomed Rahkeem Morris of  syrgapp and Clayton Samuels of  MentorWorksI \n",
      "Our MentorWorks ISA is a powerful tool in helping students find a better way to fund their education  With our fund and support approach  we re aligning students and outcomes  More info  https   t co Fm0crWgzPd  fundandsupport  ISAs\n",
      "How you present yourself to potential employers and contacts is important  Do you have relatable and stories of impact to share  https   t co yPlSuxo6Pp\n",
      " CraftOurStory  razashaikh Happy to provide any additional info \n",
      " CraftOurStory  razashaikh Thanks for the connection   razashaikh  In addition to interest free  ISAs  we also offer career development  amp  direct access to employers for our students   fundandsupport\n",
      "Take the time to craft  amp  tailor your resume for the specific role you re applying to  It makes a huge impact  https   t co aX53odlKe3\n"
     ]
    }
   ],
   "source": [
    "#Authenticate credentials\n",
    "\n",
    "#Twitter credentials for the app\n",
    "consumer_key = 'ELRou1VKpS5p7EBEGamXqqGRT'\n",
    "consumer_secret = 'QbsToHJOyA9ZsDrFCCw1aErF9LubwqlfLpLcJviruhKepQwX3D'\n",
    "access_key= '3138259520-6jOClvoHXzF5DCf2XaylTxhrn1Rb7X50ykQyU3C'\n",
    "access_secret = 'r9bokM5UvRbS8QnsYdQksSi2tO8gRj7T4sfq2K41jzmQM'\n",
    "\n",
    "#Pass twitter credentials to tweepy\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#set two date variables for date range\n",
    "#start_date = '2018-10-01'\n",
    "#end_date = '2018-10-31'\n",
    " \n",
    "tweets = tweepy.Cursor(api.user_timeline, screen_name='MentorworksISA',lang='en', tweet_mode = 'extended').items(10)\n",
    "file = open(\"searchTweets.csv\", 'a',newline='')\n",
    "alltweets = csv.writer(file)\n",
    "#for page in tweets:\n",
    "#        for status in page:\n",
    "#            new_entry = []\n",
    "#            status = status._json\n",
    "#            print(status)\n",
    "#            print(status['created_at'])\n",
    "for tweet in tweets:\n",
    "    status = tweet._json\n",
    "    #print(status)\n",
    "    created_at =  status['created_at'] # accessing tweet time\n",
    "    tweet_id = status['id_str']         # accessing tweet id\n",
    "    tweet_text = status['full_text']     # accessing tweet text\n",
    "    tweet_text = re.sub(r'\\W',' ', tweet_text) # Remove special characters    \n",
    "    print(tweet_text)\n",
    "    alltweets.writerow([created_at, tweet_id, tweet_text])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5083333333333333\n",
      "1.0\n",
      "1.0\n",
      "0.03333333333333333\n",
      "1.0\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "1.0\n",
      "0.4666666666666666\n",
      "0.5125\n"
     ]
    }
   ],
   "source": [
    "# Sentiment analysis\n",
    "\n",
    "file =open(\"searchTweets.csv\", 'r')\n",
    "alltweets = csv.reader(file)\n",
    "\n",
    "sentiment_file = open(\"sentimenttweets.csv\", \"w\",newline='')\n",
    "sntTweets = csv.writer(sentiment_file)\n",
    "\n",
    "for row in alltweets:\n",
    "    blob = TextBlob(row[2])\n",
    "    print(blob.sentiment.subjectivity)\n",
    "    if blob.sentiment.polarity > 0:   \n",
    "        sntTweets.writerow([row[0], row[1], row[2], blob.sentiment.polarity, \"positive\"])\n",
    "    elif blob.sentiment.polarity < 0:\n",
    "        sntTweets.writerow([row[0], row[1], row[2], blob.sentiment.polarity, \"negative\"])\n",
    "    elif blob.sentiment.polarity == 0.0:\n",
    "        sntTweets.writerow([row[0], row[1], row[2], blob.sentiment.polarity, \"neutral\"])   \n",
    "        \n",
    "file.close()\n",
    "sentiment_file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MentorWorks  team has been working remotely for more than a week now  amp  we re trying different things to stay connected to each other  virtual coffee chats  lunches and happy hours via  zoom   We re looking for other ideas too   what are you doing  XrTerra  amp   StackEducation  \n",
      "['The', 'MentorWorks', 'team', 'has', 'been', 'working', 'remotely', 'for', 'more', 'than', 'a', 'week', 'now', 'amp', 'we', 're', 'trying', 'different', 'things', 'to', 'stay', 'connected', 'to', 'each', 'other', 'virtual', 'coffee', 'chats', 'lunches', 'and', 'happy', 'hours', 'via', 'zoom', 'We', 're', 'looking', 'for', 'other', 'ideas', 'too', 'what', 'are', 'you', 'doing', 'XrTerra', 'amp', 'StackEducation']\n",
      "[Sentence(\"The MentorWorks  team has been working remotely for more than a week now  amp  we re trying different things to stay connected to each other  virtual coffee chats  lunches and happy hours via  zoom   We re looking for other ideas too   what are you doing  XrTerra  amp   StackEducation\")]\n",
      "Sentiment(polarity=0.15833333333333335, subjectivity=0.5083333333333333)\n",
      "####Singularization###\n",
      "MentorWorks\n",
      "MentorWork\n",
      "####Pluralization###\n",
      "team\n",
      "teams\n",
      "####Lemmatization###\n",
      "has\n",
      "have\n",
      "I have good spelling!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kkris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from textblob import Word\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "# Tokenization\n",
    "\n",
    "file =open(\"searchTweets.csv\", 'r')\n",
    "alltweets = csv.reader(file)\n",
    "\n",
    "tweet_line =alltweets.__next__()[2]\n",
    "\n",
    "print(tweet_line)\n",
    "\n",
    "blob = TextBlob(tweet_line)\n",
    "print(blob.words)\n",
    "print(blob.sentences)\n",
    "print(blob.sentiment)\n",
    "# Stemming and Lemmatization\n",
    " \n",
    "#print(blob.words[23])\n",
    "print('####Singularization###')\n",
    "print(blob.words[1])\n",
    "print(blob.words[1].singularize())\n",
    "\n",
    "print('####Pluralization###')\n",
    "print(blob.words[2])\n",
    "print(blob.words[2].pluralize())\n",
    "\n",
    "print('####Lemmatization###')\n",
    "print(blob.words[3])\n",
    "w=Word(blob.words[3])\n",
    "print(w.lemmatize(\"v\"))\n",
    "\n",
    "### # Spelling correction\n",
    "b = TextBlob(\"I havv goood speling!\")\n",
    "print(b.correct())\n",
    "\n",
    "file.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Excited to hear how @MentorWorksISA and @EdmitEDU are tackling the student debt crisis @VentureCafe. #Boston… https://t.co/yBQEhDWjXG', 'Getting ready to lead a discussion about @MentorWorksISA and how we’re using our #fundandsupport model to provide a… https://t.co/akYcz6ytG8']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
